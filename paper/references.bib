% This file was created with Citavi 6.4.0.0

@inproceedings{murase1996automatic,
  title={Automatic making of sokoban problems},
  author={Murase, Yoshio and Matsubara, Hitoshi and Hiraga, Yuzuru},
  booktitle={Pacific Rim International Conference on Artificial Intelligence},
  pages={592--600},
  year={1996},
  organization={Springer}
}

@article{culberson1997sokoban,
  title={Sokoban is PSPACE-complete},
  author={Culberson, Joseph},
  journal={Technical Reports (Computing Science)},
  organization={University of Alberta},
  year={1997}
}

@inproceedings{taylor2011procedural,
  title={Procedural generation of sokoban levels},
  author={Taylor, Joshua and Parberry, Ian},
  booktitle={Proceedings of the International North American Conference on Intelligent Games and Simulation},
  pages={5--12},
  year={2011}
}

@inproceedings{taylor2015attention,
  author = {Taylor, Joshua and Parberry, Ian and Parsons, Thomas},
  year = {2015},
  booktitle={Proceedings of the Foundations of Digital Games},
  title = {Comparing Player Attention on Procedurally Generated vs. Hand Crafted Sokoban Levels with an Auditory Stroop Test}
}

@inproceedings{kartal2016data,
  title={Data driven Sokoban puzzle generation with Monte Carlo tree search},
  author={Kartal, Bilal and Sohre, Nick and Guy, Stephen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={12},
  number={1},
  year={2016}
}

@article{de2019procedural,
  title={Procedural puzzle generation: a survey},
  author={De Kegel, Barbara and Haahr, Mads},
  journal={IEEE Transactions on Games},
  volume={12},
  number={1},
  pages={21--40},
  year={2019},
  publisher={IEEE}
}

@misc{SokobanOfficial,
  title = {Sokoban {{Official}}},
  abstract = {The official website of the puzzle game "sokoban"},
  howpublished = {\url{https://sokoban.jp/title.html}},
  journal = {Sokoban Official Site},
}

@article{haslumIntroductionPlanningDomain2019a,
  title = {An {{Introduction}} to the {{Planning Domain Definition Language}}},
  author = {Haslum, Patrik and Lipovetzky, Nir and Magazzeni, Daniele and Muise, Christian},
  year = {2019},
  month = {apr},
  volume = {13},
  pages = {1--187},
  publisher = {{Morgan \& Claypool Publishers}},
  issn = {1939-4608},
  doi = {10.2200/S00900ED2V01Y201902AIM042},
  journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  number = {2},
}

@book{ghallab2016automated,
  title = {Automated Planning and Acting},
  author = {Ghallab, Malik and Nau, Dana and Traverso, Paolo},
  year = {2016},
  publisher = {{Cambridge University Press}},
}

@misc{ipc,
  title={The International Planning Competition},
  author={Pommerening, F and Torralba, A and Balyo, T, and Vallati, Mauro and Chrpa, Lukas and McCluskey, Lee},
  howpublished = {\url{https://www.icaps-conference.org/competitions/}},
  year={1998--2018}
}

@article{lisp86,
  title = {{{LISP}}. {{Second}} Edition},
  author = {Winston, P H and Horn, B K},
  year = {1986},
  month = {jan},
  address = {{United States}},
  annotation = {Abstract Note: In this edition, the authors redirect the orientation of the text towards the Common LISP dialect, an amalgam of the features of the dialects which have evolved from the LISP programming language. The authors introduce discussions of procedure abstraction and data abstraction; add an introduction to message-passing and object-centred programming, and have revised the chapters on mathematical examples, natural-language interfaces, symbolic pattern matching, and rule-based expert systems.},
}

@article{fengNovelAutomatedCurriculum,
  title = {A {{Novel Automated Curriculum Strategy}} to {{Solve Hard Sokoban Planning Instances}}},
  author = {Feng, Dieqiao and Gomes, Carla P and Selman, Bart},
  pages = {12},
  abstract = {In recent years, we have witnessed tremendous progress in deep reinforcement learning (RL) for tasks such as Go, Chess, video games, and robot control. Nevertheless, other combinatorial domains, such as AI planning, still pose considerable challenges for RL approaches. The key difficulty in those domains is that a positive reward signal becomes exponentially rare as the minimal solution length increases. So, an RL approach loses its training signal. There has been promising recent progress by using a curriculum-driven learning approach that is designed to solve a single hard instance. We present a novel automated curriculum approach that dynamically selects from a pool of unlabeled training instances of varying task complexity guided by our difficulty quantum momentum strategy. We show how the smoothness of the task hardness impacts the final learning results. In particular, as the size of the instance pool increases, the ``hardness gap'' decreases, which facilitates a smoother automated curriculum based learning process. Our automated curriculum approach dramatically improves upon the previous approaches. We show our results on Sokoban, which is a traditional PSPACE-complete planning problem and presents a great challenge even for specialized solvers. Our RL agent can solve hard instances that are far out of reach for any previous state-of-the-art Sokoban solver. In particular, our approach can uncover plans that require hundreds of steps, while the best previous search methods would take many years of computing time to solve such instances. In addition, we show that we can further boost the RL performance with an intricate coupling of our automated curriculum approach with a curiosity-driven search strategy and a graph neural net representation.},
  file = {/home/froleyks/Zotero/storage/WCGM7JF8/Feng et al. - A Novel Automated Curriculum Strategy to Solve Har.pdf},
  language = {en},
}
